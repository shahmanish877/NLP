{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# PoS Tagger\n",
        "\n",
        "\n",
        "A Part-of-Speech (POS) tagger, also known as a POS Tagger, is a component of natural language processing that assigns parts-of-speech labels to words in a text based on their grammatical and syntactical context within a sentence. Parts of speech refer to the linguistic categories that words can be classified into, such as nouns, verbs, adjectives, adverbs, pronouns, conjunctions, prepositions, and more. POS tagging is an essential task in various NLP applications, as it provides information about the grammatical roles and relationships between words in a sentence, which helps in understanding the meaning and structure of the text.\n",
        "\n",
        "For example, consider the sentence: \"The cat is sleeping peacefully.\" A POS tagger would assign the following parts-of-speech labels to the words:\n",
        "\n",
        "    \"The\": Determiner (DT)\n",
        "    \"cat\": Noun (NN)\n",
        "    \"is\": Verb (VBZ)\n",
        "    \"sleeping\": Verb (VBG)\n",
        "    \"peacefully\": Adverb (RB)\n",
        "\n",
        "\n",
        "There are various approaches to POS tagging, ranging from rule-based methods to statistical and machine learning-based methods like Hidden Markov Models (HMMs), Conditional Random Fields (CRFs), and neural network-based models. These methods learn patterns from labeled training data and use them to predict the most likely POS tag for each word in a given sentence.\n"
      ],
      "metadata": {
        "id": "FGwf49wq3Yxm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train and use HMM based tagger\n",
        "\n",
        "\n",
        "The nltk.tag.hmm module in NLTK provides classes and functions for working with Hidden Markov Models (HMMs) for part-of-speech tagging and other sequence labeling tasks. HMMs are a statistical model that can be used to model sequential data, where the current state is influenced by the previous state and emits observations (labels) according to certain probabilities.\n",
        "\n",
        "In the context of the NLTK's hmm module, the primary use is for training and using Hidden Markov Model-based taggers, which are commonly used for part-of-speech tagging. Here's a brief overview of the main functionalities and uses of the `nltk.tag.hmm` module:\n",
        "\n",
        "- **Training an HMM Tagger:**\n",
        "The module provides a `HiddenMarkovModelTrainer` class that allows you to train an HMM-based tagger using a tagged corpus. You can use this trainer to estimate the transition probabilities between different states (tags) and the emission probabilities (observations given states) from your training data.\n",
        "\n",
        "- **Tagging with an HMM Tagger:**\n",
        "Once you have trained an HMM tagger using the `HiddenMarkovModelTrainer`, you can use the trained tagger to tag new sequences of observations (usually words). The tagger assigns the most likely sequence of states (tags) to the given sequence of observations based on the learned probabilities.\n",
        "\n",
        "- **Customizing HMM Parameters:**\n",
        "The `HiddenMarkovModelTagger` class allows you to create a custom HMM tagger by specifying your own states, symbols (observations), transitions, and emission probabilities. This can be useful if you want to fine-tune the model or incorporate additional information.\n",
        "\n",
        "- **Using Word Distributions:**\n",
        "The HMM tagger works with probability distributions for transitions and emissions. You can provide your own probability distributions or let the trainer estimate them from the training data."
      ],
      "metadata": {
        "id": "-_rdNkBvXBD_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dmnLr3vF2P1f"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.tag import hmm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('treebank')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_TXvBoRZ2Xqn",
        "outputId": "497f01c7-3332-4d65-8fd8-d48a93397fb0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/treebank.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import treebank, wordnet"
      ],
      "metadata": {
        "id": "hgu3J1x82WFE"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the tagged corpus (for training and evaluation)\n",
        "corpus = treebank.tagged_sents()\n",
        "corpus[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTKjyDKG2hN0",
        "outputId": "ca61679e-af17-40c3-afa4-ca56aade46b8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Pierre', 'NNP'),\n",
              " ('Vinken', 'NNP'),\n",
              " (',', ','),\n",
              " ('61', 'CD'),\n",
              " ('years', 'NNS'),\n",
              " ('old', 'JJ'),\n",
              " (',', ','),\n",
              " ('will', 'MD'),\n",
              " ('join', 'VB'),\n",
              " ('the', 'DT'),\n",
              " ('board', 'NN'),\n",
              " ('as', 'IN'),\n",
              " ('a', 'DT'),\n",
              " ('nonexecutive', 'JJ'),\n",
              " ('director', 'NN'),\n",
              " ('Nov.', 'NNP'),\n",
              " ('29', 'CD'),\n",
              " ('.', '.')]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a basic HMM tagger\n",
        "trainer = hmm.HiddenMarkovModelTrainer()\n",
        "basic_tagger = trainer.train(corpus)"
      ],
      "metadata": {
        "id": "jAOQiXhW2kH0"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the custom tagger\n",
        "test_sentence = \"The quick brown fox jumps over the lazy dog\"\n",
        "tokens = nltk.word_tokenize(test_sentence)\n",
        "tags = basic_tagger.tag(tokens)\n",
        "print(tags)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8d4X50w2yIL",
        "outputId": "6dcf3eca-80c1-4f95-f2c8-6dda1eb37376"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('The', 'DT'), ('quick', 'JJ'), ('brown', 'NNP'), ('fox', 'NNP'), ('jumps', 'NNP'), ('over', 'NNP'), ('the', 'NNP'), ('lazy', 'NNP'), ('dog', 'NNP')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  TNT (Trigrams 'n' Tags)\n",
        "\n",
        "The TNT (Trigrams 'n' Tags) corpus, also known as the TnT tagset, is a resource used for part-of-speech tagging and morphological analysis. It is widely known for its association with the TnT (Trigrams 'n' Tags) statistical tagger, which is a part-of-speech tagging system based on trigram probabilities. The TnT tagger uses the frequencies of trigrams (sequences of three words or tags) to predict the next tag in a sequence.\n",
        "\n",
        "The TNT corpus is used for training and evaluating statistical taggers like TnT. It includes tagged text data where each word is associated with its corresponding part-of-speech tag. This tagged data serves as the basis for estimating the probabilities used by the trigram-based tagger.\n"
      ],
      "metadata": {
        "id": "4lKv6Tho35u8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tag import tnt\n",
        "from nltk.corpus import treebank\n",
        "\n",
        "train = treebank.tagged_sents()[:1000]\n",
        "test = treebank.tagged_sents()[1000:1250]\n",
        "tagg = tnt.TnT()\n",
        "tagg.train(train)\n",
        "print (\"Accuracy of TnT Tagging : \", tagg.accuracy(test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8XM3il9365t",
        "outputId": "f9f1a9bd-6322-4102-d0cf-44c8edd5e79c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of TnT Tagging :  0.7964917727413847\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(treebank.tagged_sents()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2YUpGIo4Kdm",
        "outputId": "9a514c99-577e-4926-c1c5-86c1bea47f60"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3914\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(train[:2])\n",
        "sent = \"Lets us try to tag this sentence\"\n",
        "tokens = sent.split(' ')\n",
        "tagg.tag(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UFss_ej4eMv",
        "outputId": "afad9292-7a8c-4dd4-8a0a-fd7a5a03777f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Lets', 'Unk'),\n",
              " ('us', 'PRP'),\n",
              " ('try', 'VB'),\n",
              " ('to', 'TO'),\n",
              " ('tag', 'Unk'),\n",
              " ('this', 'DT'),\n",
              " ('sentence', 'Unk')]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## spaCy pos tagger\n",
        "\n",
        "spaCy is an open-source natural language processing (NLP) library for Python that provides tools and functionalities for various NLP tasks. It is designed to be fast, efficient, and easy to use, making it a popular choice for both research and production-level applications. spaCy offers pre-trained models for various languages and supports a wide range of NLP tasks, such as tokenization, part-of-speech tagging, named entity recognition, dependency parsing, text classification, and more."
      ],
      "metadata": {
        "id": "UECA0IRYY4m4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy"
      ],
      "metadata": {
        "id": "1TvMK8N5ZFzY"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_lg"
      ],
      "metadata": {
        "id": "cRFZKbZyax70"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load('en_core_web_lg')"
      ],
      "metadata": {
        "id": "cW4yMybua6yL"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"He was being opposed by her without any reason. A plan is being prepared by charles for next project\"\n",
        "for token in nlp(sentence):\n",
        "    print(f'{token.text:{10}} {token.tag_:>{10}}\\t{spacy.explain(token.tag_):<{50}} {token.pos_:>{5}}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CrwAmOnMbQ5M",
        "outputId": "2640c73b-50eb-48e3-a6b8-c52153f10e6f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "He                PRP\tpronoun, personal                                   PRON\n",
            "was               VBD\tverb, past tense                                     AUX\n",
            "being             VBG\tverb, gerund or present participle                   AUX\n",
            "opposed           VBN\tverb, past participle                               VERB\n",
            "by                 IN\tconjunction, subordinating or preposition            ADP\n",
            "her               PRP\tpronoun, personal                                   PRON\n",
            "without            IN\tconjunction, subordinating or preposition            ADP\n",
            "any                DT\tdeterminer                                           DET\n",
            "reason             NN\tnoun, singular or mass                              NOUN\n",
            ".                   .\tpunctuation mark, sentence closer                  PUNCT\n",
            "A                  DT\tdeterminer                                           DET\n",
            "plan               NN\tnoun, singular or mass                              NOUN\n",
            "is                VBZ\tverb, 3rd person singular present                    AUX\n",
            "being             VBG\tverb, gerund or present participle                   AUX\n",
            "prepared          VBN\tverb, past participle                               VERB\n",
            "by                 IN\tconjunction, subordinating or preposition            ADP\n",
            "charles           NNP\tnoun, proper singular                              PROPN\n",
            "for                IN\tconjunction, subordinating or preposition            ADP\n",
            "next               JJ\tadjective (English), other noun-modifier (Chinese)   ADJ\n",
            "project            NN\tnoun, singular or mass                              NOUN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Brill Tagger\n",
        "\n",
        "Brill’s transformational rule-based tagger. Brill taggers use an initial tagger (such as `tag.DefaultTagger`) to assign an initial tag sequence to a text; and then apply an ordered list of transformational rules to correct the tags of individual tokens. These transformation rules are specified by the `TagRule` interface.\n",
        "\n",
        "Brill taggers can be created directly, from an initial tagger and a list of transformational rules; but more often, Brill taggers are created by learning rules from a training corpus, using one of the TaggerTrainers available."
      ],
      "metadata": {
        "id": "SEkrwIn5bxnJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('brown')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gVAEN4VjcWU1",
        "outputId": "5ae8286a-5c98-413f-d894-71a8193ff40e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import brown\n",
        "from nltk.tag import brill, brill_trainer\n",
        "from nltk.tag.util import untag\n",
        "\n",
        "# Load the Brown corpus and divide it into sentences\n",
        "corpus = brown.tagged_sents(categories='news')\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "train_data = corpus[:3000]\n",
        "test_data = corpus[3000:]\n",
        "\n",
        "# Define the baseline tagger (in this case, a default tagger)\n",
        "baseline_tagger = nltk.DefaultTagger('NN')\n",
        "\n",
        "# Create templates for Brill Tagger rules\n",
        "templates = [\n",
        "    brill.Template(brill.Pos([-1])),\n",
        "    brill.Template(brill.Pos([1])),\n",
        "    brill.Template(brill.Pos([-2])),\n",
        "    brill.Template(brill.Pos([2])),\n",
        "    brill.Template(brill.Pos([-2, -1])),\n",
        "    brill.Template(brill.Pos([1, 2])),\n",
        "    brill.Template(brill.Pos([-3, -2, -1])),\n",
        "    brill.Template(brill.Pos([1, 2, 3])),\n",
        "    brill.Template(brill.Word([-1])),\n",
        "    brill.Template(brill.Word([1])),\n",
        "    brill.Template(brill.Word([-2])),\n",
        "    brill.Template(brill.Word([2])),\n",
        "    brill.Template(brill.Word([-2, -1])),\n",
        "    brill.Template(brill.Word([1, 2])),\n",
        "    brill.Template(brill.Word([-3, -2, -1])),\n",
        "    brill.Template(brill.Word([1, 2, 3])),\n",
        "]\n",
        "\n",
        "# Train a Brill Tagger\n",
        "trainer = brill_trainer.BrillTaggerTrainer(baseline_tagger, templates, trace=3)\n",
        "brill_tagger = trainer.train(train_data, max_rules=10)\n",
        "\n",
        "# Evaluate the tagger on the test data\n",
        "accuracy = brill_tagger.evaluate(test_data)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Tag a sample sentence\n",
        "sample_sentence = \"NLTK is a great library for natural language processing.\"\n",
        "words = nltk.word_tokenize(sample_sentence)\n",
        "tags = brill_tagger.tag(words)\n",
        "print(tags)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8oFcrKFrcTSH",
        "outputId": "f8f8d903-55df-4f5f-a7db-58a60da0080a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TBL train (fast) (seqs: 3000; tokens: 64638; tpls: 16; min score: 2; min acc: None)\n",
            "Finding initial useful rules...\n",
            "    Found 280917 useful rules.\n",
            "\n",
            "           B      |\n",
            "   S   F   r   O  |        Score = Fixed - Broken\n",
            "   c   i   o   t  |  R     Fixed = num tags changed incorrect -> correct\n",
            "   o   x   k   h  |  u     Broken = num tags changed correct -> incorrect\n",
            "   r   e   e   e  |  l     Other = num tags changed incorrect -> incorrect\n",
            "   e   d   n   r  |  e\n",
            "------------------+-------------------------------------------------------\n",
            "19712010  391457  | NN->IN if Word:the@[1]\n",
            "34933493   0  13  | NN->AT if Pos:IN@[-1]\n",
            " 5491001 4524534  | NN->NP if Word:,@[-2,-1]\n",
            "26642664   0  45  | NN->, if Pos:NP@[1]\n",
            " 478 517  39 443  | NN->VB if Word:to@[-1]\n",
            " 603 603   0 357  | NN->TO if Pos:VB@[1]\n",
            " 420 429   9  96  | NN->NP if Word:Mrs.@[-3,-2,-1]\n",
            " 368 387  19 559  | NN->IN if Word:a@[1]\n",
            " 963 963   0   2  | NN->AT if Pos:IN@[-1]\n",
            " 211 211   0   0  | IN->, if Pos:NP@[2]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-3d2cf0effc8d>:41: DeprecationWarning: \n",
            "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
            "  instead.\n",
            "  accuracy = brill_tagger.evaluate(test_data)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.300256153246464\n",
            "[('NLTK', 'NN'), ('is', 'IN'), ('a', 'AT'), ('great', 'NN'), ('library', 'NN'), ('for', 'NN'), ('natural', 'NN'), ('language', 'NN'), ('processing', 'NN'), ('.', 'NN')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check other POS Taggers as well: [Reference](https://medium.com/@yashj302/pos-tagging-nlp-python-41df5243da78)"
      ],
      "metadata": {
        "id": "aSSa4e7PXHjm"
      }
    }
  ]
}