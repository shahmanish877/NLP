{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-09-16T02:05:36.015404900Z",
     "start_time": "2023-09-16T02:05:35.883270500Z"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "text = [\n",
    "    'probability to make predictions',\n",
    "\t'to address noisy data, i.e. cleaning data by removing outliers, handling missing values, etc. log transform, replace missing by mean, median, etc.',\n",
    "\t'to address scant data - data that are limited or inadequate - small amount of data',\n",
    "\t'data mirroring, rotation, adding random noise'\n",
    "\t'statistics maa mean, median haru parxa.....central tendency & distribution bare maa vanxa',\n",
    "    'hypothesis testing, regression……hypothesis i.e. h0 or h1 test garera variable maa relation xa ki xaina herxa'\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-16T02:05:36.057295600Z",
     "start_time": "2023-09-16T02:05:35.899408200Z"
    }
   },
   "id": "3d995c36d864c118"
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "# preprocess\n",
    "sentences = []\n",
    "word_set = []"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-16T02:05:36.057295600Z",
     "start_time": "2023-09-16T02:05:35.915187900Z"
    }
   },
   "id": "36c8b512e24e7b96"
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "for sent in text:\n",
    "    x = [i.lower() for i in word_tokenize(sent) if i.isalpha()]\n",
    "    sentences.append(x)\n",
    "    for word in x:\n",
    "        if word not in word_set:\n",
    "            word_set.append(word)\n",
    "word_set = set(word_set)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-16T02:05:36.057295600Z",
     "start_time": "2023-09-16T02:05:35.921843900Z"
    }
   },
   "id": "d25b035904c04a2a"
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'by', 'herxa', 'hypothesis', 'limited', 'maa', 'relation', 'scant', 'data', 'xa', 'handling', 'mirroring', 'missing', 'bare', 'test', 'median', 'or', 'noisestatistics', 'that', 'ki', 'small', 'adding', 'address', 'rotation', 'make', 'mean', 'distribution', 'variable', 'haru', 'of', 'probability', 'parxa', 'tendency', 'etc', 'testing', 'to', 'garera', 'replace', 'noisy', 'amount', 'xaina', 'predictions', 'vanxa', 'values', 'removing', 'log', 'transform', 'inadequate', 'central', 'cleaning', 'are', 'outliers', 'random'}\n"
     ]
    }
   ],
   "source": [
    "print(word_set)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-16T02:05:36.057295600Z",
     "start_time": "2023-09-16T02:05:35.932989100Z"
    }
   },
   "id": "4763aa799c9e210d"
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'by': 1, 'herxa': 1, 'hypothesis': 1, 'limited': 1, 'maa': 2, 'relation': 1, 'scant': 1, 'data': 3, 'xa': 1, 'handling': 1, 'mirroring': 1, 'missing': 1, 'bare': 1, 'test': 1, 'median': 2, 'or': 2, 'noisestatistics': 1, 'that': 1, 'ki': 1, 'small': 1, 'adding': 1, 'address': 2, 'rotation': 1, 'make': 1, 'mean': 2, 'distribution': 1, 'variable': 1, 'haru': 1, 'of': 1, 'probability': 1, 'parxa': 1, 'tendency': 1, 'etc': 1, 'testing': 1, 'to': 3, 'garera': 1, 'replace': 1, 'noisy': 1, 'amount': 1, 'xaina': 1, 'predictions': 1, 'vanxa': 1, 'values': 1, 'removing': 1, 'log': 1, 'transform': 1, 'inadequate': 1, 'central': 1, 'cleaning': 1, 'are': 1, 'outliers': 1, 'random': 1}\n"
     ]
    }
   ],
   "source": [
    "def count_dict(sentences):\n",
    "    word_count = {}\n",
    "    for word in word_set:\n",
    "        word_count[word] = 0\n",
    "        for sent in sentences:\n",
    "            if word in sent:\n",
    "                word_count[word] += 1\n",
    "    return word_count\n",
    "\n",
    "word_count = count_dict(sentences)\n",
    "print(word_count)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-16T02:05:36.057295600Z",
     "start_time": "2023-09-16T02:05:35.940852800Z"
    }
   },
   "id": "167fbcee08cddeaa"
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "# term freq\n",
    "def term_freq(document, word):\n",
    "    N = len(document)\n",
    "    occurance = len([w for w in document if w == word])\n",
    "    return occurance/N"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-16T02:05:36.057295600Z",
     "start_time": "2023-09-16T02:05:35.948605600Z"
    }
   },
   "id": "53f1954a4f80c15f"
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-16T02:05:36.057295600Z",
     "start_time": "2023-09-16T02:05:35.955659200Z"
    }
   },
   "id": "43c0ba20bffd6fbd"
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "total_documents = len(sentences)\n",
    "def inverse_doc_freq(word):\n",
    "    word_occurance = word_count[word]\n",
    "    log = np.log(total_documents/word_occurance)\n",
    "    return log"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-16T02:05:36.057295600Z",
     "start_time": "2023-09-16T02:05:35.963021800Z"
    }
   },
   "id": "79e7d7efa2cb067b"
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "index_dict = {} #Dictionary to store index for each word\n",
    "i = 0\n",
    "for word in word_set:\n",
    "    index_dict[word] = i\n",
    "    i += 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-16T02:05:36.057295600Z",
     "start_time": "2023-09-16T02:05:35.968926700Z"
    }
   },
   "id": "45b42936ac5dc1b0"
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "def tfidf(sentence):\n",
    "    td_idf_vec = np.zeros((len(word_set),))\n",
    "    for word in sentence:\n",
    "        tf = term_freq(sentence, word)\n",
    "        idf = inverse_doc_freq(word)\n",
    "        \n",
    "        value = tf * idf\n",
    "        td_idf_vec[index_dict[word]] = value\n",
    "    return td_idf_vec"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-16T02:08:31.704924800Z",
     "start_time": "2023-09-16T02:08:31.689090100Z"
    }
   },
   "id": "74c4a4e9a479271b"
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.40235948, 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.40235948,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.12770641,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.40235948, 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        ]), array([0.1532798 , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.04865006, 0.        , 0.0766399 ,\n",
      "       0.        , 0.1532798 , 0.        , 0.        , 0.04363289,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.04363289, 0.        , 0.        , 0.04363289,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.1532798 , 0.        , 0.02432503,\n",
      "       0.        , 0.0766399 , 0.0766399 , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.0766399 , 0.0766399 , 0.0766399 ,\n",
      "       0.0766399 , 0.        , 0.        , 0.0766399 , 0.        ,\n",
      "       0.0766399 , 0.        ]), array([0.        , 0.        , 0.        , 0.11495985, 0.        ,\n",
      "       0.        , 0.11495985, 0.10946263, 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.06544934, 0.        , 0.11495985, 0.        , 0.11495985,\n",
      "       0.        , 0.06544934, 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.11495985, 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.03648754,\n",
      "       0.        , 0.        , 0.        , 0.11495985, 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.11495985, 0.        , 0.        , 0.11495985,\n",
      "       0.        , 0.        ]), array([0.        , 0.        , 0.        , 0.        , 0.10779891,\n",
      "       0.        , 0.        , 0.03004857, 0.        , 0.        ,\n",
      "       0.09467282, 0.        , 0.09467282, 0.        , 0.05389945,\n",
      "       0.        , 0.09467282, 0.        , 0.        , 0.        ,\n",
      "       0.09467282, 0.        , 0.09467282, 0.        , 0.05389945,\n",
      "       0.09467282, 0.        , 0.09467282, 0.        , 0.        ,\n",
      "       0.09467282, 0.09467282, 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.09467282, 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.09467282, 0.        , 0.        ,\n",
      "       0.        , 0.09467282]), array([0.        , 0.13411983, 0.13411983, 0.        , 0.07635756,\n",
      "       0.13411983, 0.        , 0.        , 0.13411983, 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.13411983, 0.        ,\n",
      "       0.07635756, 0.        , 0.        , 0.13411983, 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.13411983, 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.13411983, 0.        ,\n",
      "       0.13411983, 0.        , 0.        , 0.        , 0.13411983,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        ])]\n"
     ]
    }
   ],
   "source": [
    "vectors = []\n",
    "for sent in sentences:\n",
    "    vec = tfidf(sent)\n",
    "    vectors.append(vec)\n",
    "\n",
    "print(vectors)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-16T02:09:03.174124300Z",
     "start_time": "2023-09-16T02:09:03.017656200Z"
    }
   },
   "id": "59e3b27eda84cf38"
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "0.0\n",
      "0.04363289199400738\n",
      "0.06544933799101108\n"
     ]
    }
   ],
   "source": [
    "word = 'address'\n",
    "index_of_address = index_dict[word]\n",
    "print(index_of_address)\n",
    "\n",
    "print(vectors[0][index_of_address])\n",
    "print(vectors[1][index_of_address])\n",
    "print(vectors[2][index_of_address])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-16T02:15:02.345440800Z",
     "start_time": "2023-09-16T02:15:02.266754900Z"
    }
   },
   "id": "76c4d176e17203a8"
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7923336642563245 0.7875758807438265 0.49141288932039323\n"
     ]
    }
   ],
   "source": [
    "dist_doc1_doc2 = np.linalg.norm(vectors[0] - vectors[1])\n",
    "dist_doc1_doc3 = np.linalg.norm(vectors[0] - vectors[2])\n",
    "dist_doc2_doc3 = np.linalg.norm(vectors[1] - vectors[2])\n",
    "\n",
    "print(dist_doc1_doc2, dist_doc1_doc3, dist_doc2_doc3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-16T02:16:12.612982200Z",
     "start_time": "2023-09-16T02:16:12.597070600Z"
    }
   },
   "id": "63952484b687a09d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
