{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Rule based tagging\n",
        "\n",
        "When it comes to POS tagging, there are several methods that can be used to assign the appropriate tags to words in a text. One such method is the lexicon-based approach, which uses a statistical algorithm to assign the most frequently assigned POS tag to each token.\n",
        "\n",
        "For instance, the tag “verb” may be assigned to the word “run” if it is used as a verb more often than any other tag.\n",
        "\n",
        "Another approach is the rule-based method, which combines the lexicon-based approach with predefined rules. These rules are designed to handle specific cases that the lexicon-based approach may not be able to handle on its own.\n"
      ],
      "metadata": {
        "id": "onVCX3qsefmW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reading the tagset\n",
        "\n",
        "Let’s try to understand the tagged dataset by reading it from nltk."
      ],
      "metadata": {
        "id": "qCOasdSqe1A0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing libraries\n",
        "import nltk\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "id": "CS2K5DnPfNzd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('treebank')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-pzshX6mfL7x",
        "outputId": "805462c9-506c-4f78-95aa-71748ac0dfb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/treebank.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reading the Treebank tagged sentences\n",
        "wsj = list(nltk.corpus.treebank.tagged_sents())\n",
        "# samples: Each sentence is a list of (word, pos) tuples\n",
        "wsj[:3]"
      ],
      "metadata": {
        "id": "P1ow5Sn9e0ht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MACPrF-hSDSp",
        "outputId": "3e747100-daee-41f5-a545-59cdbed79bbd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100676\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Pierre', 'NNP'),\n",
              " ('Vinken', 'NNP'),\n",
              " (',', ','),\n",
              " ('61', 'CD'),\n",
              " ('years', 'NNS'),\n",
              " ('old', 'JJ'),\n",
              " (',', ','),\n",
              " ('will', 'MD'),\n",
              " ('join', 'VB'),\n",
              " ('the', 'DT')]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# converting the list of sents to a list of (word, pos tag) tuples\n",
        "tagged_words = [tup for sent in wsj for tup in sent]\n",
        "print(len(tagged_words))\n",
        "tagged_words[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EDA\n",
        "\n",
        "- Find the number of unique POS tags in the corpus\n",
        "- Which is the most frequent tag in the corpus\n",
        "- Which tag is most commonly assigned to the word \"bank\".\n",
        "- Which tag is most commonly assigned to the word \"executive\"."
      ],
      "metadata": {
        "id": "KBn8lrAsee51"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tags = [pair[1] for pair in tagged_words]\n",
        "unique_tags = set(tags)\n",
        "len(unique_tags)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NfL7HPf-f9H0",
        "outputId": "56fc6963-5582-4728-bcf2-f3ff72cfdf50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "46"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "tag_counts = Counter(tags)\n",
        "tag_counts"
      ],
      "metadata": {
        "id": "mzraVqvxgP_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tag_counts.most_common(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmlPxXR_gWvr",
        "outputId": "43c38454-7df1-4f7c-aaf9-87bfbcf0d276"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('NN', 13166), ('IN', 9857), ('NNP', 9410), ('DT', 8165), ('-NONE-', 6592)]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bank = [pair for pair in tagged_words if pair[0].lower() == 'bank']\n",
        "bank"
      ],
      "metadata": {
        "id": "p7qfffGAgZeb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "executive = [pair for pair in tagged_words if pair[0].lower() == 'executive']\n",
        "executive"
      ],
      "metadata": {
        "id": "i_IfMvyegfGi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lexicon and Rule-Based Models for POS Tagging"
      ],
      "metadata": {
        "id": "7wTMDcA9gmnp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting into Train and Test Sets\n",
        "\n",
        "train_set, test_set = train_test_split(wsj, test_size=0.3)\n",
        "print(len(train_set))\n",
        "print(len(test_set))\n",
        "print(train_set[:2])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnxqUglcgppm",
        "outputId": "1a26f210-e873-48ce-9761-16b866804cdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2739\n",
            "1175\n",
            "[[('She', 'PRP'), ('was', 'VBD'), ('untrained', 'JJ'), ('and', 'CC'), (',', ','), ('in', 'IN'), ('one', 'CD'), ('botched', 'JJ'), ('job', 'NN'), ('killed', 'VBD'), ('a', 'DT'), ('client', 'NN'), ('.', '.')], [('Similarly', 'RB'), (',', ','), ('Campbell', 'NNP'), (\"'s\", 'POS'), ('Italian', 'JJ'), ('biscuit', 'NN'), ('operation', 'NN'), (',', ','), ('D.', 'NNP'), ('Lazzaroni', 'NNP'), ('&', 'CC'), ('Co.', 'NNP'), (',', ','), ('has', 'VBZ'), ('been', 'VBN'), ('hurt', 'VBN'), ('*-40', '-NONE-'), ('by', 'IN'), ('overproduction', 'NN'), ('and', 'CC'), ('distribution', 'NN'), ('problems', 'NNS'), ('.', '.')]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Unigram lexicon tagger\n",
        "\n",
        "In NLTK, the UnigramTagger() can be used to train such a model."
      ],
      "metadata": {
        "id": "ksHzqUsVhAoN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lexicon (or unigram tagger)\n",
        "unigram_tagger = nltk.UnigramTagger(train_set)\n",
        "unigram_tagger.accuracy(test_set)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPqb4kO0g_n5",
        "outputId": "228e07dd-8e15-487c-86e2-450e927b132c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8691994391400147"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Rule-Based (Regular Expression) Tagger\n",
        "\n",
        "For example, we can specify regexes for various grammatical forms such as gerunds and past tense verbs, 3rd singular present verbs (e.g., creates, moves, makes), modal verbs (e.g., should, would, could), possessive nouns (e.g., partner’s, bank’s), plural nouns (e.g., banks, institutions), cardinal numbers (CD), and so on. In case none of these rules are applicable to a word, we can assign the most frequent tag NN to it."
      ],
      "metadata": {
        "id": "FOkB3ZL2hWYC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# specify patterns for tagging\n",
        "# example from the NLTK book\n",
        "patterns = [\n",
        "    (r'.*ing$', 'VBG'),              # gerund\n",
        "    (r'.*ed$', 'VBD'),               # past tense\n",
        "    (r'.*es$', 'VBZ'),               # 3rd singular present\n",
        "    (r'.*ould$', 'MD'),              # modals\n",
        "    (r'.*\\'s$', 'NN$'),              # possessive nouns\n",
        "    (r'.*s$', 'NNS'),                # plural nouns\n",
        "    (r'^-?[0-9]+(.[0-9]+)?$', 'CD'), # cardinal numbers\n",
        "    (r'.*', 'NN')                    # nouns\n",
        "]\n",
        "regexp_tagger = nltk.RegexpTagger(patterns)\n",
        "regexp_tagger.evaluate(test_set)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2CtnMXRhX_7",
        "outputId": "5b395bb7-5be4-496a-b4bb-a1ea164100b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-d181c6307182>:14: DeprecationWarning: \n",
            "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
            "  instead.\n",
            "  regexp_tagger.evaluate(test_set)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.21816785738131803"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Combining Rule based with Lexicon PoS Tagger\n",
        "\n",
        "NLTK provides a convenient method to combine taggers using the ‘backup’ argument. In the following code, we create a regex tagger to act as a backup to the lexicon tagger. In other words, if the lexicon tagger is unable to tag a word (e.g., a new word not in the vocabulary), it will use the rule-based tagger to assign a tag. Additionally, note that the rule-based tagger itself is backed up by the ‘NN’ tag."
      ],
      "metadata": {
        "id": "j6UJJlibhvCS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# rule based tagger\n",
        "rule_based_tagger = nltk.RegexpTagger(patterns)\n",
        "# lexicon backed up by the rule-based tagger\n",
        "lexicon_tagger = nltk.UnigramTagger(train_set, backoff=rule_based_tagger)\n",
        "lexicon_tagger.evaluate(test_set)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BMg1wLqsh4d4",
        "outputId": "d533999d-adaa-4f6c-ec45-d4b4e7b793cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-80fb3183b88f>:5: DeprecationWarning: \n",
            "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
            "  instead.\n",
            "  lexicon_tagger.evaluate(test_set)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9048541096347733"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    }
  ]
}